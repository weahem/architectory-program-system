from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
import time
import os
import re
import requests
from urllib.parse import urljoin, quote
import json

class CyberLeninkaParser:
    def __init__(self, output_dir="articles"):
        self.base_url = "https://cyberleninka.ru"
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
        self.driver = None
        self.setup_driver()
        
    def setup_driver(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome –¥—Ä–∞–π–≤–µ—Ä–∞"""
        chrome_options = Options()
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        
    def search_articles(self, query, max_results=3):
        """–ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –Ω–∞ CyberLeninka"""
        print(f"üîç –ü–æ–∏—Å–∫ —Å—Ç–∞—Ç–µ–π –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
        
        try:
            search_url = f"{self.base_url}/search?q={quote(query)}"
            self.driver.get(search_url)
            time.sleep(2)
            
            article_links = self._find_article_links(max_results)
            print(f"üìé –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å–∏: {len(article_links)}")
            
            if not article_links:
                print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å–∏")
                return []
            
            articles_data = []
            for i, article_url in enumerate(article_links[:max_results]):
                print(f"üì• –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—å—é {i+1}/{len(article_links)}...")
                
                try:
                    article_data = self._process_article_fast(article_url, i+1)
                    if article_data:
                        articles_data.append(article_data)
                        print(f"‚úÖ –°—Ç–∞—Ç—å—è {i+1} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞")
                    else:
                        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç–∞—Ç—å—é {i+1}")
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞—Ç—å–∏ {i+1}: {e}")
                    continue
                
                time.sleep(0.5)
            
            print(f"üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –£—Å–ø–µ—à–Ω–æ: {len(articles_data)}/{min(max_results, len(article_links))}")
            return articles_data
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def _find_article_links(self, max_results):
        """–ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Å—Ç–∞—Ç—å–∏"""
        article_links = []
        try:
            elements = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/article/"]')
            for element in elements:
                href = element.get_attribute("href")
                if (href and "/article/" in href and 
                    "search" not in href and 
                    href not in article_links):
                    article_links.append(href)
                    if len(article_links) >= max_results:
                        break
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å—Å—ã–ª–æ–∫: {e}")
        
        return article_links[:max_results]
    
    def _process_article_fast(self, article_url, article_number):
        """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç—å–∏ —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –ø–µ—Ä–µ—Å–∫–∞–∑–æ–º"""
        try:
            print(f"   üìÑ –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å—Ç–∞—Ç—å–∏: {article_url}")
            self.driver.get(article_url)
            time.sleep(1)
            
            title = self._get_article_title()
            print(f"   üìù –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏: {title}")
            
            safe_title = self._create_safe_filename(title)
            filename = f"{article_number:02d}_{safe_title}"
            
            article_dir = os.path.join(self.output_dir, filename)
            os.makedirs(article_dir, exist_ok=True)
            
            content_data = self._get_article_content_fast()
            if not content_data:
                return None
            
            summary = self._fast_quality_summary(content_data['content'])
            
            self._create_files_fast(article_dir, filename, title, article_url, content_data, summary)
            
            return {
                'title': title,
                'url': article_url,
                'filename': filename,
                'content': content_data['content'],
                'annotation': content_data['annotation'],
                'summary': summary,
                'directory': article_dir
            }
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç–∞—Ç—å–∏: {e}")
            return None
    
    def _get_article_content_fast(self):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç–∞—Ç—å–∏"""
        try:
            content_element = self.driver.find_element(By.CSS_SELECTOR, ".fulltext, .article-text, .content, article")
            content = content_element.text
            
            try:
                annotation_element = self.driver.find_element(By.CSS_SELECTOR, ".abstract, .annotation")
                annotation = annotation_element.text.strip()
            except:
                annotation = "–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                
            return {
                'content': content,
                'annotation': annotation
            }
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {e}")
            return {
                'content': '–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ',
                'annotation': '–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'
            }
    
    def _get_article_title(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Å—Ç–∞—Ç—å–∏"""
        try:
            element = self.driver.find_element(By.CSS_SELECTOR, 'h1, .article-title, .title')
            title = element.text.strip()
            if title and len(title) > 5 and len(title) < 200:
                return title
        except:
            pass
            
        return self.driver.title.replace(" - –ö–∏–±–µ—Ä–õ–µ–Ω–∏–Ω–∫–∞", "").strip() or f"–°—Ç–∞—Ç—å—è_{int(time.time())}"
    
    def _fast_quality_summary(self, text):
        """–ë–´–°–¢–†–´–ô –∏ –ö–ê–ß–ï–°–¢–í–ï–ù–ù–´–ô –ø–µ—Ä–µ—Å–∫–∞–∑"""
        try:
            if not text or len(text.strip()) < 100:
                return "–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–µ—Ä–µ—Å–∫–∞–∑–∞"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —á–∞—Å—Ç–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–∫–∞–∑–∞
            key_parts = self._extract_key_content(text)
            
            # –°–æ–∑–¥–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑ –ª–æ–∫–∞–ª—å–Ω–æ
            return self._create_quality_summary(key_parts)
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø–µ—Ä–µ—Å–∫–∞–∑–∞: {e}")
            return self._fallback_summary(text)
    
    def _extract_key_content(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞"""
        try:
            paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
            
            if len(paragraphs) <= 3:
                return text[:1500] if len(text) > 1500 else text
            
            # –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –æ—Ç–±–æ—Ä –∫–ª—é—á–µ–≤—ã—Ö —á–∞—Å—Ç–µ–π
            key_parts = []
            
            # –í–≤–µ–¥–µ–Ω–∏–µ (–ø–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü)
            key_parts.append(paragraphs[0])
            
            # –ö–ª—é—á–µ–≤—ã–µ –∞–±–∑–∞—Ü—ã –∏–∑ —Å–µ—Ä–µ–¥–∏–Ω—ã (2-3)
            if len(paragraphs) > 4:
                mid_point = len(paragraphs) // 2
                key_parts.extend(paragraphs[mid_point:mid_point+2])
            
            # –ó–∞–∫–ª—é—á–µ–Ω–∏–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–π –∞–±–∑–∞—Ü)
            key_parts.append(paragraphs[-1])
            
            result = "\n\n".join(key_parts)
            return result[:1500] if len(result) > 1500 else result
            
        except:
            return text[:1500] if len(text) > 1500 else text
    
    def _create_quality_summary(self, text):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ—Å–∫–∞–∑–∞"""
        try:
            paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
            
            if len(paragraphs) == 1:
                # –û–¥–∏–Ω –∞–±–∑–∞—Ü - –≤—ã–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–¥–µ—é
                content = paragraphs[0]
                sentences = re.split(r'[.!?]+', content)
                sentences = [s.strip() for s in sentences if s.strip()]
                if len(sentences) >= 3:
                    return f"–û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞: {' '.join(sentences[:2])}. –ö–ª—é—á–µ–≤–æ–π –≤—ã–≤–æ–¥: {sentences[-1]}"
                else:
                    return f"–¢–µ–º–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {content[:300]}..."
            
            elif len(paragraphs) == 2:
                # –î–≤–∞ –∞–±–∑–∞—Ü–∞ - –≤–≤–µ–¥–µ–Ω–∏–µ –∏ –æ—Å–Ω–æ–≤–Ω–æ–µ
                return f"–¢–ï–ú–ê: {paragraphs[0]}\n\n–û–°–ù–û–í–ù–û–ï –°–û–î–ï–†–ñ–ê–ù–ò–ï: {paragraphs[1][:300]}..."
            
            else:
                # –ú–Ω–æ–≥–æ –∞–±–∑–∞—Ü–µ–≤ - —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑
                intro = paragraphs[0][:200] + "..." if len(paragraphs[0]) > 200 else paragraphs[0]
                
                # –ù–∞—Ö–æ–¥–∏–º –∫–ª—é—á–µ–≤–æ–π –∞–±–∑–∞—Ü (–æ–±—ã—á–Ω–æ –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ)
                key_idx = len(paragraphs) // 2
                key_content = paragraphs[key_idx][:150] + "..." if len(paragraphs[key_idx]) > 150 else paragraphs[key_idx]
                
                conclusion = paragraphs[-1][:150] + "..." if len(paragraphs[-1]) > 150 else paragraphs[-1]
                
                return f"–í–í–ï–î–ï–ù–ò–ï: {intro}\n\n–ö–õ–Æ–ß–ï–í–ê–Ø –ò–î–ï–Ø: {key_content}\n\n–í–´–í–û–î–´: {conclusion}"
                
        except Exception as e:
            return f"–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑: {text[:300]}..."
    
    def _fallback_summary(self, text):
        """–ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–µ—Ä–µ—Å–∫–∞–∑–∞"""
        try:
            # –ü—Ä–æ—Å—Ç–æ–µ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–µ
            sentences = re.split(r'[.!?]+', text)
            sentences = [s.strip() for s in sentences if s.strip()]
            
            if len(sentences) >= 5:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 2 –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                selected = sentences[:2] + sentences[-2:]
                return " ".join(selected) + "."
            else:
                return " ".join(sentences[:3]) + "." if sentences else "–ü–µ—Ä–µ—Å–∫–∞–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        except:
            return "–ë—ã—Å—Ç—Ä—ã–π –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–µ—Ä–µ—Å–∫–∞–∑"
    
    def _create_files_fast(self, article_dir, filename, title, url, content_data, summary):
        """–ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ —Å—Ç–∞—Ç—å–∏"""
        try:
            # –û—Ä–∏–≥–∏–Ω–∞–ª (–∏–º–∏—Ç–∞—Ü–∏—è PDF)
            with open(os.path.join(article_dir, f"{filename}.pdf"), "w", encoding="utf-8") as f:
                f.write("=== –û—Ä–∏–≥–∏–Ω–∞–ª —Å—Ç–∞—Ç—å–∏ ===\n")
                f.write(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {title}\n")
                f.write(f"URL: {url}\n")
                f.write("=" * 50 + "\n\n")
                f.write(content_data['content'][:2000] + "..." if len(content_data['content']) > 2000 else content_data['content'])
            
            # TXT-–≤–µ—Ä—Å–∏—è
            with open(os.path.join(article_dir, f"{filename}.txt"), "w", encoding="utf-8") as f:
                f.write(content_data['content'])
            
            # –§–∞–π–ª –∫—Ä–∞—Ç–∫–æ–≥–æ –ø–µ—Ä–µ—Å–∫–∞–∑–∞
            with open(os.path.join(article_dir, f"{filename}_sh.txt"), "w", encoding="utf-8") as f:
                f.write(summary)
            
            # –§–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
            with open(os.path.join(article_dir, f"{filename}_an.txt"), "w", encoding="utf-8") as f:
                f.write(content_data['annotation'])
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = {
                'title': title,
                'url': url,
                'filename': filename,
                'files': {
                    'original': f"{filename}.pdf",
                    'text': f"{filename}.txt",
                    'summary': f"{filename}_sh.txt",
                    'annotation': f"{filename}_an.txt"
                }
            }
            
            with open(os.path.join(article_dir, "metadata.json"), "w", encoding="utf-8") as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {e}")
            raise
    
    def _create_safe_filename(self, title):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)
        safe_title = re.sub(r'\s+', ' ', safe_title).strip()
        safe_title = safe_title[:50]
        safe_title = safe_title.rstrip('.')
        if not safe_title:
            safe_title = "article"
        return safe_title
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞"""
        if self.driver:
            self.driver.quit()

# –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def main():
    parser = CyberLeninkaParser("articles")
    
    try:
        query = input("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π: ")
        articles = parser.search_articles(query, 3)
        
        if articles:
            print(f"\nüéâ –ù–∞–π–¥–µ–Ω–æ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π:")
            for i, article in enumerate(articles, 1):
                print(f"{i}. {article['title']}")
                print(f"   –ü–∞–ø–∫–∞: {article['directory']}")
                print(f"   –ü–µ—Ä–µ—Å–∫–∞–∑: {article['summary'][:200]}...")
                print()
        else:
            print("‚ùå –°—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    finally:
        parser.close()

if __name__ == "__main__":
    main()
